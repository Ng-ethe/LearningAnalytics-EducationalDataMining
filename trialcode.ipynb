{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download files from a url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "url = \"http://nrvis.com/data/mldata/turkiye-student-evaluation_R_Specific.csv\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('turkiye.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = \"https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-mat.csv\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('student_math.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = \"https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-por.csv\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('student_portugese.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing continous numerical values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# the continuous variables: [\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]\n",
    "\n",
    "student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]] = preprocessing.normalize(np.array(\n",
    "                                                        student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]]))\n",
    "student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]].head() # preview the normalized data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              # fro reading in data\n",
    "import matplotlib.pyplot as plt  # for visualizations\n",
    "import numpy as np               # for statistical calculations\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data into a data frame \n",
    "\n",
    "dataset_url = \"https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-mat.csv\"\n",
    "student_mat_df = pd.read_csv(dataset_url, \";\")\n",
    "student_mat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the string variables\n",
    "# some models are unable to deal with string values or do not perform well with them\n",
    "# Hence the string values require encoding\n",
    "\n",
    "# Binary values are encoded to a 1 or 0, e.g, Yes/No, Male/Female\n",
    "student_mat_df[\"school\"] = np.where(student_mat_df[\"school\"].str.contains(\"GP\", \"MS\"),1, 0)\n",
    "student_mat_df[\"sex\"] = np.where(student_mat_df[\"sex\"].str.contains(\"M\", \"F\"), 1, 0)\n",
    "student_mat_df[\"address\"] = np.where(student_mat_df[\"address\"].str.contains(\"U\", \"R\"), 1, 0)\n",
    "student_mat_df[\"famsize\"] = np.where(student_mat_df[\"famsize\"].str.contains(\"LE3\", \"GT\"), 1, 0)\n",
    "student_mat_df[\"Pstatus\"] = np.where(student_mat_df[\"Pstatus\"].str.contains(\"T\", \"A\"), 1, 0)\n",
    "student_mat_df[\"schoolsup\"] = np.where(student_mat_df[\"schoolsup\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"famsup\"] = np.where(student_mat_df[\"famsup\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"paid\"] = np.where(student_mat_df[\"paid\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"activities\"] = np.where(student_mat_df[\"activities\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"nursery\"] = np.where(student_mat_df[\"nursery\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"higher\"] = np.where(student_mat_df[\"higher\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"internet\"] = np.where(student_mat_df[\"internet\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "student_mat_df[\"romantic\"] = np.where(student_mat_df[\"romantic\"].str.contains(\"yes\", \"no\"), 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       1    0   18        1        0        0     4     4     1     5  ...   \n",
       "1       1    0   17        1        0        1     1     1     1     3  ...   \n",
       "2       1    0   15        1        1        1     1     1     1     3  ...   \n",
       "3       1    0   15        1        0        1     4     2     2     4  ...   \n",
       "4       1    0   16        1        0        1     3     3     3     3  ...   \n",
       "\n",
       "   famrel  freetime  goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0       4         3      4     1     1       3         6   5   6   6  \n",
       "1       5         3      3     1     1       3         4   5   5   6  \n",
       "2       4         3      2     2     3       3        10   7   8  10  \n",
       "3       3         2      2     1     1       5         2  15  14  15  \n",
       "4       4         3      2     1     2       5         4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, dictionary has been used to replace the string values \n",
    "# as a form of encoding the categorical data\n",
    "\n",
    "labels = student_mat_df['Mjob'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'Mjob' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "student_mat_df.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "labels = student_mat_df['Fjob'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'Fjob' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "student_mat_df.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "labels = student_mat_df['guardian'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'guardian' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "student_mat_df.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "labels = student_mat_df['reason'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'reason' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "student_mat_df.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "student_mat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n",
      "Statistics=0.373, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "sex\n",
      "Statistics=0.635, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "age\n",
      "Statistics=0.911, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "address\n",
      "Statistics=0.513, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famsize\n",
      "Statistics=0.568, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Pstatus\n",
      "Statistics=0.349, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Medu\n",
      "Statistics=0.861, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Fedu\n",
      "Statistics=0.876, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Mjob\n",
      "Statistics=0.892, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Fjob\n",
      "Statistics=0.831, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "reason\n",
      "Statistics=0.797, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "guardian\n",
      "Statistics=0.711, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "traveltime\n",
      "Statistics=0.659, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "studytime\n",
      "Statistics=0.834, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "failures\n",
      "Statistics=0.507, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "schoolsup\n",
      "Statistics=0.394, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famsup\n",
      "Statistics=0.618, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "paid\n",
      "Statistics=0.634, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "activities\n",
      "Statistics=0.636, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "nursery\n",
      "Statistics=0.495, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "higher\n",
      "Statistics=0.226, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "internet\n",
      "Statistics=0.450, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "romantic\n",
      "Statistics=0.595, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famrel\n",
      "Statistics=0.830, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "freetime\n",
      "Statistics=0.906, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "goout\n",
      "Statistics=0.910, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Dalc\n",
      "Statistics=0.598, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Walc\n",
      "Statistics=0.847, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "health\n",
      "Statistics=0.849, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "absences\n",
      "Statistics=0.667, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G1\n",
      "Statistics=0.975, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G2\n",
      "Statistics=0.969, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G3\n",
      "Statistics=0.929, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Shapiro-Wilk Test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import shapiro\n",
    "# normality test\n",
    "for value in range(33):\n",
    "    print(names[value])\n",
    "    stat, p = shapiro(student_mat_df.iloc[:, value])\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n",
      "Statistics=190.742, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "sex\n",
      "Statistics=1730.899, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "age\n",
      "Statistics=13.440, p=0.001\n",
      "Sample does not look Gaussian (reject H0)\n",
      "address\n",
      "Statistics=74.976, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famsize\n",
      "Statistics=194.933, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Pstatus\n",
      "Statistics=213.475, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Medu\n",
      "Statistics=128.630, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Fedu\n",
      "Statistics=231.363, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Mjob\n",
      "Statistics=24.178, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Fjob\n",
      "Statistics=17.727, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "reason\n",
      "Statistics=3252.993, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "guardian\n",
      "Statistics=1.496, p=0.473\n",
      "Sample looks Gaussian (fail to reject H0)\n",
      "traveltime\n",
      "Statistics=119.732, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "studytime\n",
      "Statistics=23.120, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "failures\n",
      "Statistics=200.329, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "schoolsup\n",
      "Statistics=170.268, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famsup\n",
      "Statistics=2065.651, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "paid\n",
      "Statistics=1751.715, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "activities\n",
      "Statistics=1718.798, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "nursery\n",
      "Statistics=84.447, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "higher\n",
      "Statistics=351.853, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "internet\n",
      "Statistics=119.696, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "romantic\n",
      "Statistics=3827.574, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "famrel\n",
      "Statistics=55.983, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "freetime\n",
      "Statistics=3.627, p=0.163\n",
      "Sample looks Gaussian (fail to reject H0)\n",
      "goout\n",
      "Statistics=27.698, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Dalc\n",
      "Statistics=185.009, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Walc\n",
      "Statistics=51.279, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "health\n",
      "Statistics=97.870, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "absences\n",
      "Statistics=345.476, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G1\n",
      "Statistics=22.612, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G2\n",
      "Statistics=16.269, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "G3\n",
      "Statistics=32.059, p=0.000\n",
      "Sample does not look Gaussian (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# D'Agostino and Pearson's Test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# normality test\n",
    "for value in range(33):\n",
    "    print(names[value])\n",
    "    stat, p = normaltest(student_mat_df.iloc[:, value])\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# the continuous variables: [\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]\n",
    "\n",
    "student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]] = preprocessing.normalize(np.array(\n",
    "                                                        student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]]))\n",
    "student_mat_df[[\"age\", \"absences\", \"G1\", \"G2\", \"G3\"]].head() # preview the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first divide our data into attributes and labels:\n",
    "#[2,6,7,12,14,13,23,24,25,26,27,28,29,30, 1,3,4,5,15,16,17,18,19,20,21,22]\n",
    "X = student_mat_df.iloc[:, 0:30 ].values  # Independent/predictor variables\n",
    "y = student_mat_df.iloc[:, 31].values    # Dependent/label variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 3, 2, 3, 3, 2, 4, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3,\n",
       "       3, 3, 2, 2, 3, 3, 3, 3, 3, 4, 3, 3, 3, 2, 4, 3, 3, 3, 3, 3, 4, 3,\n",
       "       2, 2, 3, 4, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 2, 2, 3,\n",
       "       3, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 2, 3,\n",
       "       2, 2, 2, 4, 2, 2, 3, 2, 3, 2, 3, 2, 2, 4, 3, 2, 4, 3, 2, 4, 3, 3,\n",
       "       4, 2, 3, 4, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 1, 4, 1, 1,\n",
       "       3, 3, 1, 1, 1, 1, 3, 3, 1, 2, 3, 3, 1, 3, 1, 3, 1, 2, 1, 3, 2, 1,\n",
       "       3, 2, 3, 2, 3, 3, 1, 2, 1, 2, 2, 3, 2, 3, 1, 3, 1, 3, 2, 1, 2, 2,\n",
       "       3, 2, 2, 3, 2, 3, 4, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 3, 2,\n",
       "       4, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2,\n",
       "       2, 1, 4, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 1, 3, 3,\n",
       "       1, 3, 1, 4, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 3, 3, 1, 4, 2, 3, 2,\n",
       "       1, 4, 2, 3, 2, 1, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3,\n",
       "       4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 1, 2, 3, 3, 3, 2, 3, 4, 3, 3, 4, 2,\n",
       "       3, 2, 1, 3, 3, 3, 3, 3, 1, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 3,\n",
       "       2, 3, 1, 1, 1, 3, 3, 1, 4, 2, 3, 1, 3, 1, 2, 3, 3, 2, 3, 3, 2, 3,\n",
       "       2, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 1, 2, 3, 2, 3, 3, 2,\n",
       "       4, 2, 3, 2, 3, 2, 3, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import interp\n",
    "\n",
    "y = student_mat_df['G3']\n",
    "y = interp(y,[0, 20],[1, 4]).round(0)\n",
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_mat_df.iloc[:, 0:31] =(student_mat_df.iloc[:, 0:31]).astype('category')\n",
    "\n",
    "#drinks['beer_servings'] = drinks.beer_servings.astype(float)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.538 (0.038)\n"
     ]
    }
   ],
   "source": [
    "# evaluate pca with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "#X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the pipeline\n",
    "steps = [('pca', PCA(n_components=4)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.484 (0.060)\n",
      ">2 0.532 (0.072)\n",
      ">3 0.553 (0.072)\n",
      ">4 0.537 (0.067)\n",
      ">5 0.536 (0.068)\n",
      ">6 0.521 (0.057)\n",
      ">7 0.530 (0.061)\n",
      ">8 0.524 (0.065)\n",
      ">9 0.511 (0.065)\n",
      ">10 0.505 (0.072)\n",
      ">11 0.514 (0.062)\n",
      ">12 0.516 (0.071)\n",
      ">13 0.527 (0.071)\n",
      ">14 0.540 (0.077)\n",
      ">15 0.535 (0.083)\n",
      ">16 0.532 (0.084)\n",
      ">17 0.534 (0.077)\n",
      ">18 0.532 (0.075)\n",
      ">19 0.542 (0.075)\n",
      ">20 0.542 (0.082)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare pca number of components with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "#def get_dataset():\n",
    "#\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "#\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(1,21):\n",
    "\t\tsteps = [('pca', PCA(n_components=i)), ('m', LogisticRegression())]\n",
    "\t\tmodels[str(i)] = Pipeline(steps=steps)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "#X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.xticks(rotation=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2. 2. 2. 3. 2. 3. 3. 2. 4. 3. 2. 3. 3. 3. 3. 3. 3. 2. 2. 2. 3. 3. 3. 3.\n 2. 2. 3. 3. 3. 3. 3. 4. 3. 3. 3. 2. 4. 3. 3. 3. 3. 3. 4. 3. 2. 2. 3. 4.\n 3. 2. 3. 3. 2. 3. 3. 2. 3. 3. 2. 3. 3. 3. 2. 2. 2. 3. 3. 2. 2. 3. 3. 2.\n 2. 3. 3. 2. 2. 3. 2. 2. 3. 3. 2. 3. 2. 2. 2. 3. 2. 2. 2. 4. 2. 2. 3. 2.\n 3. 2. 3. 2. 2. 4. 3. 2. 4. 3. 2. 4. 3. 3. 4. 2. 3. 4. 2. 3. 3. 3. 2. 3.\n 3. 3. 3. 3. 2. 3. 3. 2. 1. 4. 1. 1. 3. 3. 1. 1. 1. 1. 3. 3. 1. 2. 3. 3.\n 1. 3. 1. 3. 1. 2. 1. 3. 2. 1. 3. 2. 3. 2. 3. 3. 1. 2. 1. 2. 2. 3. 2. 3.\n 1. 3. 1. 3. 2. 1. 2. 2. 3. 2. 2. 3. 2. 3. 4. 2. 3. 3. 3. 3. 2. 2. 3. 2.\n 2. 2. 3. 3. 3. 2. 4. 2. 3. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 3. 3. 2. 2. 3.\n 2. 2. 2. 2. 2. 1. 4. 3. 3. 2. 3. 3. 2. 3. 3. 3. 2. 3. 2. 2. 3. 3. 3. 1.\n 3. 3. 1. 3. 1. 4. 3. 2. 2. 3. 2. 2. 2. 2. 3. 2. 3. 3. 3. 1. 4. 2. 3. 2.\n 1. 4. 2. 3. 2. 1. 2. 3. 3. 3. 2. 3. 2. 2. 2. 2. 2. 2. 3. 2. 3. 3. 4. 3.\n 3. 3. 3. 3. 3. 4. 3. 3. 1. 2. 3. 3. 3. 2. 3. 4. 3. 3. 4. 2. 3. 2. 1. 3.\n 3. 3. 3. 3. 1. 2. 2. 3. 3. 2. 3. 3. 3. 3. 3. 2. 2. 3. 2. 3. 1. 1. 1. 3.\n 3. 1. 4. 2. 3. 1. 3. 1. 2. 3. 3. 2. 3. 3. 2. 3. 2. 2. 3. 2. 3. 3. 2. 3.\n 3. 3. 2. 3. 3. 2. 3. 1. 2. 3. 2. 3. 3. 2. 4. 2. 3. 2. 3. 2. 3. 2. 2. 1.\n 2. 2. 2. 1. 2. 1. 2. 3. 2. 2. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8ce3c9262d85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# make a single prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#row = [[0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted Class: %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2. 2. 2. 3. 2. 3. 3. 2. 4. 3. 2. 3. 3. 3. 3. 3. 3. 2. 2. 2. 3. 3. 3. 3.\n 2. 2. 3. 3. 3. 3. 3. 4. 3. 3. 3. 2. 4. 3. 3. 3. 3. 3. 4. 3. 2. 2. 3. 4.\n 3. 2. 3. 3. 2. 3. 3. 2. 3. 3. 2. 3. 3. 3. 2. 2. 2. 3. 3. 2. 2. 3. 3. 2.\n 2. 3. 3. 2. 2. 3. 2. 2. 3. 3. 2. 3. 2. 2. 2. 3. 2. 2. 2. 4. 2. 2. 3. 2.\n 3. 2. 3. 2. 2. 4. 3. 2. 4. 3. 2. 4. 3. 3. 4. 2. 3. 4. 2. 3. 3. 3. 2. 3.\n 3. 3. 3. 3. 2. 3. 3. 2. 1. 4. 1. 1. 3. 3. 1. 1. 1. 1. 3. 3. 1. 2. 3. 3.\n 1. 3. 1. 3. 1. 2. 1. 3. 2. 1. 3. 2. 3. 2. 3. 3. 1. 2. 1. 2. 2. 3. 2. 3.\n 1. 3. 1. 3. 2. 1. 2. 2. 3. 2. 2. 3. 2. 3. 4. 2. 3. 3. 3. 3. 2. 2. 3. 2.\n 2. 2. 3. 3. 3. 2. 4. 2. 3. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 3. 3. 2. 2. 3.\n 2. 2. 2. 2. 2. 1. 4. 3. 3. 2. 3. 3. 2. 3. 3. 3. 2. 3. 2. 2. 3. 3. 3. 1.\n 3. 3. 1. 3. 1. 4. 3. 2. 2. 3. 2. 2. 2. 2. 3. 2. 3. 3. 3. 1. 4. 2. 3. 2.\n 1. 4. 2. 3. 2. 1. 2. 3. 3. 3. 2. 3. 2. 2. 2. 2. 2. 2. 3. 2. 3. 3. 4. 3.\n 3. 3. 3. 3. 3. 4. 3. 3. 1. 2. 3. 3. 3. 2. 3. 4. 3. 3. 4. 2. 3. 2. 1. 3.\n 3. 3. 3. 3. 1. 2. 2. 3. 3. 2. 3. 3. 3. 3. 3. 2. 2. 3. 2. 3. 1. 1. 1. 3.\n 3. 1. 4. 2. 3. 1. 3. 1. 2. 3. 3. 2. 3. 3. 2. 3. 2. 2. 3. 2. 3. 3. 2. 3.\n 3. 3. 2. 3. 3. 2. 3. 1. 2. 3. 2. 3. 3. 2. 4. 2. 3. 2. 3. 2. 3. 2. 2. 1.\n 2. 2. 2. 1. 2. 1. 2. 3. 2. 2. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# make predictions using pca with logistic regression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "#X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the model\n",
    "steps = [('pca', PCA(n_components=15)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "#row = [[0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]]\n",
    "yhat = model.predict(y)\n",
    "print('Predicted Class: %d' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier     # Decision Tree Classifier\n",
    "from sklearn.svm import SVC                         # SVM Classifier\n",
    "from sklearn.naive_bayes import GaussianNB          # Naive Bayes Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest Classifier\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state = 0, solver='lbfgs', max_iter= 1000)\n",
    "decision_classifier = DecisionTreeClassifier()\n",
    "svm_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "naive_classifier = GaussianNB().fit(X_train, y_train)\n",
    "random_classifier = RandomForestClassifier(max_depth=3, min_samples_leaf=5, random_state=0)\n",
    "\n",
    "\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "decision_classifier.fit(X_train, y_train)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "naive_classifier.fit(X_train, y_train)\n",
    "random_classifier.fit(X_train, y_train)\n",
    "\n",
    "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
    "decision_y_prediction = decision_classifier.predict(X_test) \n",
    "svm_y_prediction = svm_classifier.predict(X_test) \n",
    "knn_y_prediction = knn_classifier.predict(X_test) \n",
    "naive_y_prediction = naive_classifier.predict(X_test) \n",
    "random_y_prediction = random_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(accuracy_score(logistic_y_prediction, y_test))\n",
    "print(accuracy_score(decision_y_prediction, y_test))\n",
    "print(accuracy_score(svm_y_prediction, y_test))\n",
    "print(accuracy_score(knn_y_prediction, y_test))\n",
    "print(accuracy_score(naive_y_prediction, y_test))\n",
    "print(accuracy_score(random_y_prediction, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "nsample = 395\n",
    "np.random.seed(7654321)\n",
    "\n",
    "#A t distribution with small degrees of freedom:\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "x = stats.t.rvs(3, size=nsample)\n",
    "res = stats.probplot(x, plot=plt)\n",
    "\n",
    "#A t distribution with larger degrees of freedom:\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "x = stats.t.rvs(25, size=nsample)\n",
    "res = stats.probplot(x, plot=plt)\n",
    "\n",
    "#A mixture of two normal distributions with broadcasting:\n",
    "\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "x = stats.norm.rvs(loc=[0,5], scale=[1,1.5],\n",
    "                   size=(nsample//2,2)).ravel()\n",
    "res = stats.probplot(x, plot=plt)\n",
    "\n",
    "#A standard normal distribution:\n",
    "\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "x = stats.norm.rvs(loc=0, scale=1, size=nsample)\n",
    "res = stats.probplot(x, plot=plt)\n",
    "\n",
    "#Produce a new figure with a loggamma distribution, using the dist and sparams keywords:\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = stats.loggamma.rvs(c=2.5, size=500)\n",
    "res = stats.probplot(x, dist=stats.loggamma, sparams=(2.5,), plot=ax)\n",
    "ax.set_title(\"Probplot for loggamma dist with shape parameter 2.5\")\n",
    "\n",
    "#Show the results with Matplotlib:\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
